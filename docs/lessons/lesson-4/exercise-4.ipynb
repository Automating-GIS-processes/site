{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5c2a5d1",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "\n",
    "> **Deadline:**  \n",
    "> Please complete this exercise **by the end of day** on Thursday, 28 November, 2024 (the day of next week’s work session).\n",
    "\n",
    "\n",
    "To start this assignment, [accept the GitHub Classroom\n",
    "assignment](https://classroom.github.com/a/qiULH4id), and clone *your own*\n",
    "repository, e.g., in a [CSC\n",
    "Noppe](../../course-info/course-environment)\n",
    "instance. Make sure you commit and push all changes you make (you can\n",
    "revisit instructions on how to use `git` and the jupyterlab git-plugin\n",
    "on the [website of the Geo-Python\n",
    "course](https://geo-python-site.readthedocs.io/en/latest/lessons/l2/git-basics.html).\n",
    "\n",
    "To preview the exercise without logging in, you can find the open course copy\n",
    "of the course’s GitHub repository at\n",
    "[github.com/automating-gis-processes-2024/exercise-4](https://github.com/Automating-GIS-processes-II-2024/exercise-4).\n",
    "Don’t attempt to commit changes to that repository, but rather work with your\n",
    "personal GitHub Classroom copy (see above).\n",
    "\n",
    "\n",
    "## Hints\n",
    "\n",
    "### Joining two data frames on different column names\n",
    "\n",
    "We have already joined data sets that share the same index, and also used\n",
    "*spatial joins* to merge geo-data frames depending on their geometric\n",
    "relationships.\n",
    "\n",
    "For *problem 1*, it might be handy to be able to join two data sets using\n",
    "the values of two columns that have a different name. One good approach is to\n",
    "set the index of both data frames to refer to the same column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e86aeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "df1 = pandas.DataFrame({\n",
    "    \"id\": [1, 2, 3],\n",
    "    \"other_column\": [\"a\", \"b\", \"c\"]\n",
    "})\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5158b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pandas.DataFrame({\n",
    "    \"id\": [67, 68, 69],\n",
    "    \"other_other_column\": [\"x\", \"y\", \"z\"],\n",
    "    \"df1_id\": [1, 2, 3]\n",
    "})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d5a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_df = df1.set_index(\"id\").join(df2.set_index(\"df1_id\"))\n",
    "joint_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411fd247",
   "metadata": {},
   "source": [
    "### Renaming columns when joining data frames\n",
    "\n",
    "It is often necessary to rename columns when we join data frames that have\n",
    "duplicate column names. In the example below, both `df1` and `df2` have a\n",
    "column `other_column`; the join fails. An appropriate fix is to add a suffix\n",
    "to all columns of one or both of the data frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdcc2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "df1 = pandas.DataFrame({\n",
    "    \"id\": [1, 2, 3],\n",
    "    \"other_column\": [\"a\", \"b\", \"c\"]\n",
    "})\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c468cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pandas.DataFrame({\n",
    "    \"id\": [67, 68, 69],\n",
    "    \"other_other_column\": [\"x\", \"y\", \"z\"],\n",
    "    \"df1_id\": [1, 2, 3]\n",
    "})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e49f2a5",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "# Will fail, because duplicate column names exist:\n",
    "joint_df = df1.join(df2)\n",
    "joint_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f9b690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# works: add a suffix to one of the data sets’ columns\n",
    "joint_df = df1.join(df2.add_suffix(\"_df2\"))\n",
    "joint_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2e15bb",
   "metadata": {},
   "source": [
    "### Searching for files using a pattern\n",
    "\n",
    "In [Lesson\n",
    "2](../lesson-2/geopandas-an-introduction)\n",
    "we discussed how to use a file pattern to search for files, using\n",
    "[`pathlib.Path.glob()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.glob).\n",
    "\n",
    "To loop over all files ending in `_s.shp` inside `DATA_DIRECTORY /\n",
    "\"finland_topographic_database`, use the following piece of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0037ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "DATA_DIRECTORY = pathlib.Path().resolve() / \"data\"\n",
    "\n",
    "for input_file in (DATA_DIRECTORY / \"finland_topographic_database\").glob(\"*_s.shp\"):\n",
    "    print(input_file.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea35450",
   "metadata": {},
   "source": [
    "This will come in handy for *problem 2*, when reading in all travel time data\n",
    "files. Be sure to revisit the explanation in [Lesson\n",
    "2](../lesson-2/geopandas-an-introduction).\n",
    "\n",
    "\n",
    "### Find the minimum value across multiple columns\n",
    "\n",
    "For *problem 2*, you have to find the smallest value across multiple columns:\n",
    "the shortest travel time to any of the eight shopping centres. For this,\n",
    "[`panda`’s `DataFrame.min()`\n",
    "method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.min.html)\n",
    "can come in handy. It identifies the smallest value in each column or row (it\n",
    "accepts the same `axis=` parameter as `apply()`).\n",
    "\n",
    "For instance, to find the smalles value for each row across the columns `a`,\n",
    "`b`, and `c` of the data frame below, use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59177cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "df = pandas.DataFrame(\n",
    "    {\n",
    "        \"id\": [1, 2, 3],\n",
    "        \"a\": [27, 64, 12],\n",
    "        \"b\": [13, 13, 13],\n",
    "        \"c\": [34, 15, 1]\n",
    "    }\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d0e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select which columns to compare, then call `.min()`\n",
    "df[[\"a\", \"b\", \"c\"]].min(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c9609",
   "metadata": {},
   "source": [
    "To find out which column had the smallest value for each row, use the\n",
    "near-identical method\n",
    "[`idxmin()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.idxmin.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e10353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"a\", \"b\", \"c\"]].idxmin(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93def3ec",
   "metadata": {},
   "source": [
    "Of course, equivalent methods to find the greatest values exist: they are named\n",
    "[`pandas.DataFrame.max()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.max.html)\n",
    "and\n",
    "[`pandas.DataFrame.idxmax()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.idxmax.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90377ce1031e5e97",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Custom classification with `mapclassify`\n",
    "\n",
    "`mapclassify.UserDefined` allows grouping data into **custom classes** based on predefined breakpoints. This method is ideal for thematic mapping and tailoring classifications to specific ranges.\n",
    "<br>\n",
    "\n",
    "**yb:** Short for \"yielded bins,\" this attribute contains the class index for each data value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0a64c2e07a426c4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from mapclassify import UserDefined\n",
    "\n",
    "# Sample data\n",
    "data = {\"region\": [\"A\", \"B\", \"C\", \"D\", \"E\"], \"population_density\": [120, 450, 800, 300, 1500]}\n",
    "gdf = gpd.GeoDataFrame(data)\n",
    "\n",
    "# Define custom breakpoints\n",
    "breaks = [200, 500, 1000, 2000]\n",
    "\n",
    "# Classify data with UserDefined\n",
    "classifier = UserDefined(gdf[\"population_density\"], bins=breaks)\n",
    "gdf[\"class\"] = classifier.yb  # Assign class indices to a new column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
